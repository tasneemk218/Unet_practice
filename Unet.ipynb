{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\"\"\" Convolutional block:\n",
        "    It follows a two 3x3 convolutional layer, each followed by a batch normalization and a relu activation.\n",
        "\"\"\"\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\"\"\" Encoder block:\n",
        "    It consists of an conv_block followed by a max pooling.\n",
        "    Here the number of filters doubles and the height and width half after every block.\n",
        "\"\"\"\n",
        "class encoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = conv_block(in_c, out_c)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        p = self.pool(x)\n",
        "\n",
        "        return x, p\n",
        "\n",
        "\"\"\" Decoder block:\n",
        "    The decoder block begins with a transpose convolution, followed by a concatenation with the skip\n",
        "    connection from the encoder block. Next comes the conv_block.\n",
        "    Here the number filters decreases by half and the height and width doubles.\n",
        "\"\"\"\n",
        "class decoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = conv_block(out_c+out_c, out_c)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class build_unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        self.e1 = encoder_block(3, 64)\n",
        "        self.e2 = encoder_block(64, 128)\n",
        "        self.e3 = encoder_block(128, 256)\n",
        "        self.e4 = encoder_block(256, 512)\n",
        "\n",
        "        \"\"\" Bottleneck \"\"\"\n",
        "        self.b = conv_block(512, 1024)\n",
        "\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        self.d1 = decoder_block(1024, 512)\n",
        "        self.d2 = decoder_block(512, 256)\n",
        "        self.d3 = decoder_block(256, 128)\n",
        "        self.d4 = decoder_block(128, 64)\n",
        "\n",
        "        \"\"\" Classifier \"\"\"\n",
        "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        s1, p1 = self.e1(inputs)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "        \"\"\" Bottleneck \"\"\"\n",
        "        b = self.b(p4)\n",
        "\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        \"\"\" Classifier \"\"\"\n",
        "        outputs = self.outputs(d4)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # inputs = torch.randn((2, 32, 256, 256))\n",
        "    # e = encoder_block(32, 64)\n",
        "    # x, p = e(inputs)\n",
        "    # print(x.shape, p.shape)\n",
        "    #\n",
        "    # d = decoder_block(64, 32)\n",
        "    # y = d(p, x)\n",
        "    # print(y.shape)\n",
        "\n",
        "    inputs = torch.randn((2, 3, 512, 512))\n",
        "    model = build_unet()\n",
        "    y = model(inputs)\n",
        "    print(y.shape)"
      ],
      "metadata": {
        "id": "asnsBTmpjGiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13fb04f-8d20-48e9-963d-94e224d2b870"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.  Importing Libraries: The code begins by importing the necessary libraries, including torch for PyTorch and nn for defining neural network layers\n",
        "\n",
        "2. **conv_block Clas**s: This class defines a convolutional block, which is a basic building block of the U-Net. It contains two convolutional layers with batch normalization and ReLU activation functions. The purpose of this block is to learn features from the input.\n",
        "\n",
        "3. **encoder_block Class**: An encoder block consists of a conv_block followed by max-pooling. Max-pooling reduces the spatial dimensions of the feature maps while increasing the number of filters. This class is responsible for downsampling the input.\n",
        "\n",
        "4. **decoder_block Class**: A decoder block is used in the decoding part of the U-Net. It begins with a transpose convolution (also known as deconvolution or upsampling), followed by concatenation with the skip connection from the corresponding encoder block. Then, another conv_block is applied to learn features. This block is responsible for upsampling the feature maps.\n",
        "\n",
        "5. **build_unet Class**: This class defines the complete U-Net architecture. It includes the encoder, bottleneck (central block), and decoder. The number of filters in each encoder block doubles, while in the decoder block, it decreases by half. The classifier layer at the end produces the final output.\n",
        "\n",
        "6. **forward Method in build_unet Clas**s: This method specifies the forward pass of the U-Net. It first passes the input through the encoder, then the bottleneck, and finally the decoder. Skip connections are used to concatenate the feature maps from the encoder to the corresponding decoder layers. The classifier layer produces the final output.\n",
        "\n",
        "7. **if __name__ == \"__main__\"** Block: This block provides an example of how to use the defined classes. It creates random input data and passes it through the U-Net model, printing the shape of the output\n",
        "\n"
      ],
      "metadata": {
        "id": "WcO7Qeu4l5KU"
      }
    }
  ]
}